{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exiftool import *\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Work directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images\"\n",
    "work_dir = \"/mnt/c/Users/bhatta53/Documents/tmp_image/\"\n",
    "metadata_file = work_dir + 'metadata.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work dir: /mnt/c/Users/bhatta53/Documents/tmp_image/\n",
      "/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images**/*.[jJ][pP][gG]\n",
      "ext jpg: 10566\n",
      "/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images**/*.[jJ][pP][eE][gG]\n",
      "ext jpeg: 2404\n",
      "/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images**/*.[nN][eE][fF]\n",
      "ext nef: 0\n",
      "/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images**/*.[pP][nN][gG]\n",
      "ext png: 0\n",
      "/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images**/*.[cC][rR][22]\n",
      "ext cr2: 0\n",
      "/mnt/c/Users/bhatta53/Documents/drive/OneDrive - Nanyang Technological University/personal/redmi_note_7_backup_2021_06/Images**/*.[pP][eE][fF]\n",
      "ext pef: 0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "print(f\"Work dir: {work_dir}\")\n",
    "\n",
    "# instantiate exiftool\n",
    "\n",
    "\n",
    "# discover the files \n",
    "image_ext = ['jpg', 'jpeg', 'nef', 'png', 'cr2', 'pef']\n",
    "all_metadata = list()\n",
    "for ext in image_ext:\n",
    "    search_pattern = image_dir + '**/*.' \n",
    "    for ch in ext: \n",
    "        up = ch.upper()\n",
    "        low = ch.lower()\n",
    "        search_pattern = search_pattern + '[' + low + up+']'\n",
    "    print(search_pattern)\n",
    "    files = glob.glob(search_pattern, recursive=True)\n",
    "    print(f'ext {ext}: {len(files)}')\n",
    "    \n",
    "  \n",
    "    if files != []:\n",
    "        # get the metadata using exiftool\n",
    "        with exiftool.ExifTool() as et:\n",
    "            metadata = et.get_metadata_batch(files)\n",
    "        all_metadata = all_metadata + metadata \n",
    "\n",
    "import pickle\n",
    "with open(metadata_file, 'wb') as handle:\n",
    "    pickle.dump(all_metadata, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016:01:01 [22, 37, 23, 19, 27, 31, 25] ['2016:07:30', '2016:08:20', '2016:10:09', '2016:10:22', '2016:10:24', '2016:11:06', '2016:11:08'] ['2016:07:31', '2016:08:21', '2016:10:10', '2016:10:23', '2016:10:25', '2016:11:07', '2016:11:09']\n",
      "2017:01:01 [] [] []\n",
      "2018:01:01 [16, 19, 15, 170, 17, 19] ['2018:08:11', '2018:08:24', '2018:09:02', '2018:10:15', '2018:10:24', '2018:10:29'] ['2018:08:12', '2018:08:25', '2018:09:03', '2018:10:19', '2018:10:25', '2018:10:30']\n",
      "2019:01:01 [101, 22, 16, 16, 18, 19, 18] ['2019:03:03', '2019:03:07', '2019:03:12', '2019:04:22', '2019:05:26', '2019:08:28', '2019:09:21'] ['2019:03:05', '2019:03:08', '2019:03:13', '2019:04:23', '2019:05:27', '2019:08:29', '2019:09:22']\n",
      "2020:01:01 [15, 35, 83] ['2020:07:19', '2020:09:12', '2020:09:26'] ['2020:07:20', '2020:09:13', '2020:09:27']\n",
      "2021:01:01 [17, 76, 23, 37, 36, 15, 69, 15, 36, 15, 21] ['2021:01:16', '2021:01:31', '2021:02:21', '2021:02:26', '2021:03:13', '2021:03:17', '2021:03:19', '2021:03:25', '2021:04:03', '2021:05:23', '2021:06:03'] ['2021:01:17', '2021:02:01', '2021:02:22', '2021:02:27', '2021:03:14', '2021:03:18', '2021:03:20', '2021:03:26', '2021:04:04', '2021:05:24', '2021:06:04']\n"
     ]
    }
   ],
   "source": [
    "# create an in-memory dataframe \n",
    "import pandas as pd \n",
    "import datetime \n",
    "with open(metadata_file, 'rb') as handle:\n",
    "    metadata = pickle.load(handle)\n",
    "\n",
    "complete_data = dict()\n",
    "meta_tags = ['filename', 'width', 'height', 'timestamp']\n",
    "for d in meta_tags:\n",
    "   complete_data[d] = [] \n",
    "\n",
    "for data in metadata:\n",
    "    \n",
    "    f = data[\"SourceFile\"]\n",
    "    if 'File:ImageHeight' in data.keys():\n",
    "        height, width  = data['File:ImageHeight'], data['File:ImageWidth']\n",
    "    else:\n",
    "        height, width = 0,0\n",
    "    \n",
    "    \n",
    "    if \"EXIF:DateTimeOriginal\" in data.keys():\n",
    "        ts = data[\"EXIF:DateTimeOriginal\"]\n",
    "    elif 'EXIF:GPSTimeStamp' in data.keys():\n",
    "        # 2016:07:30 18:50:27\n",
    "        ts = '{} {}'.format(data['EXIF:GPSDateStamp'],data['EXIF:GPSTimeStamp'])\n",
    "    else:\n",
    "        ts = ''\n",
    "    complete_data['filename'].append(f)\n",
    "    complete_data['width'].append(width)\n",
    "    complete_data['height'].append(height)\n",
    "    complete_data['timestamp'].append(ts)\n",
    "\n",
    "df = pd.DataFrame(complete_data)\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     print(row['timestamp'])\n",
    "    \n",
    "\n",
    "def event_detector(df, threshold, start_date, end_date, time_dir, dummy=True):\n",
    "    ''' from the dataframe, extract events. \n",
    "        An event is a day which has >= threshold images. \n",
    "        If consecutive days have events, then they are merged into a single event.\n",
    "        The files are copied to the time_dir. dummy should be set to False to actually\n",
    "        copy the files.\n",
    "    '''\n",
    "    sorted_df = df.sort_values(['timestamp'])\n",
    "    mask = (df['timestamp'] >= start_date) & (df['timestamp'] <= end_date)\n",
    "    relevant_df = sorted_df.loc[mask]\n",
    "    \n",
    "    event_dict = dict()\n",
    "    keys = ['start_date', 'end_date', 'event_count']\n",
    "    for k in keys:\n",
    "        event_dict[k] = []\n",
    "    \n",
    "    # lets find events\n",
    "    # event = a day with >= threshold number of photos \n",
    "    # if consecutive days >= threshold, then merge \n",
    "    curr_event = None \n",
    "    event_start = None\n",
    "    event_end = None \n",
    "    last_date_str = None \n",
    "    for index, row in relevant_df.iterrows():\n",
    "        curr_ts = row['timestamp'][:row['timestamp'].find(' ')]     \n",
    "        curr_date = datetime.datetime.strptime(curr_ts, '%Y:%m:%d')\n",
    "        end_date  = curr_date + datetime.timedelta(days=1)\n",
    "        \n",
    "        curr_date_str = curr_date.strftime('%Y:%m:%d')\n",
    "        end_date_str = end_date.strftime('%Y:%m:%d')\n",
    "        \n",
    "        if curr_date_str == last_date_str:\n",
    "            continue \n",
    "        \n",
    "        today_events = (df['timestamp'] >= curr_date_str) & (df['timestamp'] < end_date_str)\n",
    "        today_df = relevant_df.loc[today_events]\n",
    "#         print(curr_date_str, len(today_df))\n",
    "        event_count = len(today_df)\n",
    "        if event_count >= threshold:\n",
    "            # is it a new event ?\n",
    "            if curr_event == None:\n",
    "                curr_event = curr_date_str\n",
    "                event_start = curr_date_str\n",
    "                event_end = end_date_str\n",
    "            # is it part of an old event\n",
    "            else:\n",
    "                event_end = curr_date_str\n",
    "                \n",
    "        else: # there were no events today\n",
    "            if curr_event != None:\n",
    "                event_dict['start_date'].append(event_start) \n",
    "                event_dict['end_date'].append(event_end) \n",
    "                events = (df['timestamp'] >= event_start) & (df['timestamp'] < event_end)\n",
    "                event_count = 0\n",
    "                for v in events:\n",
    "                    if v:\n",
    "                        event_count = event_count+1\n",
    "                event_dict['event_count'].append(event_count)\n",
    "                # create an event dir in the year dir \n",
    "                event_dir = time_dir + event_start.replace(':', '_')\n",
    "                if not os.path.isdir(event_dir):\n",
    "                    os.mkdir(event_dir)\n",
    "                event_dir = event_dir + '/'\n",
    "                event_df = relevant_df.loc[events]\n",
    "                fc_ = 0\n",
    "                for index, row in event_df.iterrows():\n",
    "                    file = row['filename']\n",
    "                    dest_file = os.path.basename(file)\n",
    "                    ext = dest_file[dest_file.rfind('.'):]\n",
    "                    ts = row['timestamp']\n",
    "                    if ' ' in ts:\n",
    "                        ts = ts[:ts.find(' ')]\n",
    "                        ts = ts.replace(':', '_')\n",
    "                    fname = ts + f'_e{fc_}'+ ext\n",
    "                    fc_ = fc_ + 1\n",
    "                    dest = event_dir +  fname\n",
    "                    if not dummy:\n",
    "                        shutil.copy2(file, dest)\n",
    "                        \n",
    "                # drop these images \n",
    "                df.drop()\n",
    "                    \n",
    "                curr_event = None \n",
    "            # copy the current day files to the year dir \n",
    "            fc_ = 0\n",
    "            for index, row in today_df.iterrows():\n",
    "                file = row['filename']\n",
    "                dest_file = os.path.basename(file)\n",
    "                ext = dest_file[dest_file.rfind('.'):]\n",
    "                name = curr_date_str.replace(':', '_')\n",
    "                if ' ' in name:\n",
    "                    name = name[:name.find(' ')]\n",
    "                fname = name + f'_{fc_}'+ ext\n",
    "                dest = time_dir +  fname\n",
    "#                 print(dest)\n",
    "                fc_ = fc_ + 1\n",
    "                if not dummy:\n",
    "                    shutil.copy2(file, dest)\n",
    "            \n",
    "        \n",
    "        last_date_str = curr_date_str\n",
    "    print(start_date, event_dict['event_count'], event_dict['start_date'], event_dict['end_date'])\n",
    "    \n",
    "threshold = 15  \n",
    "for year in range(2016,2022):\n",
    "    # create a directory inside the work directory if not already present\n",
    "    year_dir = work_dir + f'{year}'\n",
    "    if not os.path.isdir(year_dir):\n",
    "        os.mkdir(year_dir)\n",
    "    event_detector(df, threshold, f'{year}:01:01',  f'{year}:12:31', year_dir+'/')        \n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitee0bae73b0ef4403a4475f789faa8b57"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
